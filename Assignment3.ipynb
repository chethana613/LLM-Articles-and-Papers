{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC5YfdwivLvhXlg/9E3/TP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chethana613/LLM-Readings-and-Assignments/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HZ68Cr66khH",
        "outputId": "09d4cdfc-2b49-434d-b1d1-5307ed27fad2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.14.1-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import openai\n",
        "\n",
        "def extract_alone_sentiment(response):\n",
        "    sentiment = response.choices[0].message.content.split(\"\\n\")[1].strip()\n",
        "    return sentiment\n",
        "\n",
        "def query_gpt(prompts):\n",
        "    openai.api_key = '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'\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are an expert in predicting the sentiment of a given prompt\"}]\n",
        "\n",
        "    user_prompts = []\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        user_prompt = f\"Predict the sentiment of the following prompt ({i+1}/{len(prompts)}): '{prompt}' into one of the following three categories: neutral, negative, positive. The sentiment shouldn't be blank or ''. For example, your output should be in this format 'positive'.\"\n",
        "        user_prompts.append(user_prompt)\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": \"\\n\".join(user_prompts)})\n",
        "\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        print(f\"Response:{response}\")\n",
        "        predicted_labels = []\n",
        "\n",
        "        # Extracting predicted sentiments\n",
        "        for i, sentiment in enumerate(response.choices[0].message.content.split(\"\\n\")[1:], 1):\n",
        "            print(f\"Sentiment:{sentiment}\")\n",
        "            sentiment = sentiment.split(\".\")[1]\n",
        "            print(f\"Modified Sentiment:{sentiment}\")\n",
        "            if sentiment:  # Exclude empty lines\n",
        "                predicted_labels.append(sentiment.strip())\n",
        "        print(f\"predicted_labels:{predicted_labels}\")\n",
        "        return predicted_labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the OpenAI API request: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "dataset = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\", split='test')\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "positive_samples = [sample for sample, label_id in zip(dataset['text'], dataset['label']) if labels[label_id] == 'positive'][:25]\n",
        "negative_samples = [sample for sample, label_id in zip(dataset['text'], dataset['label']) if labels[label_id] == 'negative'][:25]\n",
        "prompts = positive_samples + negative_samples\n",
        "\n",
        "true_labels.extend(['positive'] * 25 + ['negative'] * 25)\n",
        "\n",
        "print(f\"Prompts: {prompts}\")\n",
        "predicted_labels = query_gpt(prompts)\n",
        "print(f\"True Labels: {true_labels},{len(true_labels)}\")\n",
        "print(f\"Predicted Labels: {predicted_labels},{len(predicted_labels)}\")\n",
        "\n",
        "if predicted_labels and true_labels:\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    metrics = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "    classification_report_output = classification_report(true_labels, predicted_labels, target_names=['positive', 'negative'])\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {metrics[0]}\")\n",
        "    print(f\"Recall: {metrics[1]}\")\n",
        "    print(f\"F1-score: {metrics[2]}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report_output)\n",
        "else:\n",
        "    print(\"Error: No predicted labels were returned.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIWEkryI1nKV",
        "outputId": "8dbdecf2-322f-417b-c5ee-ca719a095bda"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts: ['@user You are a stand up guy and a Gentleman Vice President Pence ', \"i'm not even catholic, but pope francis is my dude. like i just need him to hug me and tell me everything is okay. \", 'Samsung to Bring Android 7.0 Nougat to Galaxy S6, S6 edge, Note 5, and Tab S2 - Softpedia News ', \"I will go so far to say s1 of westworld isn't just good, it's brilliant. A story within a story within a story about storytelling \", '#NationalFastFoodDay Would love to live there. Chick-fil-A üòç ', 'The Reputation Doctor weighs in on Tony Romo #NFL @user joins @user on #TheMorningRush LISTEN: ', 'So proud of way @user & #trumpTransitionteam are molding strong leadership group for #America #TeamTrump #MakeAmericaGreatAgain ', '@user @user - #ScreamQueens so lucky to get to work with TK. ', 'This is a big deal and a smart move by Microsoft: ', 'Digesting while watching #ScreamQueens s1 Thanksgiving & Black Friday eps. SO SO GOOD!! ', \"I've been listening to Leonard Cohen nonstop for the past month. Only to find out he passed literally weeks ago. Wow my heart is so overwhel \", 'Listen to #NBAwards Winner @user interview on @user ', \"Kelly Anne Conway is here reporting the wall is a glorious 10 meters high, while Ben Carson counters that 'meters' arent even a real thing \", 'Grayson Allen & Lonzo Ball the best players in college basketball. ', \"FINALLY watching Love & Happiness!!!  This country is going to miss your family's class, wisdom, love, and patience. #ThankYouObama \", '#MPN #OneDirection#MtvStarsNiallHoran JESUSüòçüòçüòçüòçüòç ', \"If you wanna have some seasonal fun & #teachecon #Hatchimals are today's Cabbage Patch Kids & Tickle Me Elmo Christ‚Ä¶ \", 'Look at Kierra doing her good singing and growling today. #ThankYouObama ', '#ThisIsUs = my new fav series üëäüèæ ', \"It's incredible how many people are born in November... if u think about it, that means they were conceived in february...(VALENTINES DAY) \", 'I liked a @user video from @user Persona 5 - E3 Gameplay Analysis ', \"Our #MannequinChallenge it's only 10 secs tho üòÇüòÇüòÇ \", \"Yeah where's season 2 gonna go? Incredible season finale yo #WestWorld \", 'Bob Dylan is the greatest. ', \"So is @user gonna sing the #BeautyAndTheBeast theme song? Cos I mean it'd be really great if she did. It'd be perfect, actually... \", 'Trying to have a conversation with my dad about vegetarianism is the most pointless infuriating thing ever #caveman ', \"@user @user @user Looks like Flynn isn't too pleased with me, he blocked me. You blocked by Flynn too @user \", '@user for al the crying you do about how middle America is left out-they have twice as much voting power ', 'Israel deems comatose Gaza man who needs treatment in West Bank  a security threat. #Palestine  via @user ', 'Iraqi Forces set to storm 3 areas of #Mosul, #AlQahira, #alMasarif &  #alAmn#MosulOps#mosuloffensive#iraq#ISIS‚Ä¶ ', 'Electoral College must reject Trump #rejecttrump #notmypresident #takingbackdemocracy #blacklivesmatter #nevertrump ', 'Stop #fracking #Cuadrilla persecuting land defenders through the legal system #BankruptCuadrilla #ECOCIDE ', \"@user Everyone's thinking far too short-termed. When all fossil fuels run out with no substitutes, then the crisis will come. \", '@user @user @user Why is it that today society is casually comfortable about being pubicly distasteful?#deplorables ', \"Ben Carson for Housing & Urban Development?? üòê I just can't üòí \", \"Israel's New Racism: Persecution of African Migrants in Holy Land #gaza #palestine #israel #BDS \", \"@user She just didn't get them in areas were she needed them. Lots of voter suppression going on. Hacking & tamperingüíô \", 'Pelosi should go no matter ', \"I'm doing a speech on animal testing and it is so fucking horrible oh my god \", \"@user Coward... well... why doesn't Poroshenko or Avakov or Saakasjvili travel to Crimea? \", \"-- @user your statement for Mitt to apologize is not a qualifier for him as SOS Trump's transition is ASKING its an Insult. \", '@user last thing @user needs is a self-promoting $ laundering medicare fraud scammer, voter fraud.. rese‚Ä¶ ', 'This reminds me of that time I got attacked by Alt-rightists: ', 'Taylor Shit doing the #mannequinchallenge here in the great state of Rhode Island means that the mannequin challenge is #cancelled. ', '\"Are we out of touch, sexually deviant, decadent dilettantes who can\\'t own up to our misrule?No it is the deplora‚Ä¶ ', 'Mooreder When Michael Moore picks up your cause, then wrecks you. \"He so called out the DNC! It was mooreder I tells ya!\" #UsefulNewVerbs ', \"Donald Trump does not have a clue about global warming. Maybe the Rockefeller's can clue them in about fossil fuels. \", '#TV #Bullshit They are saying #Brexit was not about Closing borders and leaving the single market?? FUNNY THAT ?? STOP BULLSHITING US ', '‚ÄúPharmaceutical companies are being affected by these lower numbers in so many states across the country.‚Äù ', '@user By this logic, we shouldn\\'t have lifted embargo on Cuba b/c it was \"long standing policy.\" ']\n",
            "Response:ChatCompletion(id='chatcmpl-93xvLOVgC5Njq41OIJcZ7JPljDKKj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Predicted sentiment:\\n1. positive\\n2. positive\\n3. positive\\n4. positive\\n5. positive\\n6. positive\\n7. positive\\n8. positive\\n9. positive\\n10. positive\\n11. positive\\n12. positive\\n13. negative\\n14. positive\\n15. positive\\n16. positive\\n17. positive\\n18. positive\\n19. positive\\n20. positive\\n21. positive\\n22. positive\\n23. positive\\n24. positive\\n25. positive\\n26. negative\\n27. negative\\n28. negative\\n29. negative\\n30. negative\\n31. negative\\n32. negative\\n33. negative\\n34. negative\\n35. negative\\n36. negative\\n37. negative\\n38. negative\\n39. negative\\n40. negative\\n41. negative\\n42. negative\\n43. negative\\n44. negative\\n45. negative\\n46. negative\\n47. negative\\n48. negative\\n49. negative\\n50. negative', role='assistant', function_call=None, tool_calls=None))], created=1710732359, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=203, prompt_tokens=3672, total_tokens=3875))\n",
            "Sentiment:1. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:2. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:3. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:4. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:5. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:6. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:7. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:8. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:9. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:10. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:11. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:12. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:13. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:14. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:15. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:16. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:17. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:18. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:19. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:20. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:21. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:22. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:23. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:24. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:25. positive\n",
            "Modified Sentiment: positive\n",
            "Sentiment:26. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:27. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:28. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:29. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:30. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:31. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:32. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:33. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:34. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:35. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:36. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:37. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:38. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:39. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:40. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:41. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:42. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:43. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:44. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:45. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:46. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:47. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:48. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:49. negative\n",
            "Modified Sentiment: negative\n",
            "Sentiment:50. negative\n",
            "Modified Sentiment: negative\n",
            "predicted_labels:['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative']\n",
            "True Labels: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative'],50\n",
            "Predicted Labels: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative'],50\n",
            "Accuracy: 0.98\n",
            "Precision: 0.9807692307692308\n",
            "Recall: 0.98\n",
            "F1-score: 0.9799919967987194\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.96      1.00      0.98        25\n",
            "    negative       1.00      0.96      0.98        25\n",
            "\n",
            "    accuracy                           0.98        50\n",
            "   macro avg       0.98      0.98      0.98        50\n",
            "weighted avg       0.98      0.98      0.98        50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import openai\n",
        "\n",
        "def extract_alone_sentiment(response):\n",
        "    sentiment = response.choices[0].message.content.split(\"\\n\")[1].strip()\n",
        "    return sentiment\n",
        "\n",
        "def query_gpt(prompts):\n",
        "    openai.api_key = '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'\n",
        "    messages = [{\"role\": \"system\", \"content\": f\"You are an expert in predicting the sentiment of all the given '{len(prompts)}' prompts. You will exactly return one of 'positive' or 'negative' in lowercases for each of the prompt without any prefix.\"}]\n",
        "\n",
        "    user_prompts = []\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        user_prompt = f\"Predict for this prompt: '{prompt}'.\"\n",
        "        user_prompts.append(user_prompt)\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": \"\\n\".join(user_prompts)})\n",
        "\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        print(f\"Response:{response}\")\n",
        "        predicted_labels = []\n",
        "\n",
        "        # Extracting predicted sentiments\n",
        "        for sentiment in response.choices[0].message.content.split(\"\\n\"):\n",
        "            if sentiment:  # Exclude empty lines\n",
        "                # Split by \":\" and take the last part\n",
        "                print(f\"Predicted Sentiment: {sentiment}\")\n",
        "                sentiment = sentiment.split(\": \")[-1].strip()\n",
        "                print(f\"Modified Sentiment: {sentiment}\")\n",
        "                predicted_labels.append(sentiment)\n",
        "        print(f\"predicted_labels: {predicted_labels}\")\n",
        "        return predicted_labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the OpenAI API request: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "dataset = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\", split='test')\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "N = 5\n",
        "\n",
        "positive_samples = [sample for sample, label_id in zip(dataset['text'], dataset['label']) if labels[label_id] == 'positive'][:N]\n",
        "negative_samples = [sample for sample, label_id in zip(dataset['text'], dataset['label']) if labels[label_id] == 'negative'][:N]\n",
        "prompts = positive_samples + negative_samples\n",
        "\n",
        "true_labels.extend(['positive'] * N + ['negative'] * N)\n",
        "\n",
        "print(f\"Prompts: {prompts}\")\n",
        "predicted_labels = query_gpt(prompts)\n",
        "print(f\"True Labels: {true_labels},{len(true_labels)}\")\n",
        "print(f\"Predicted Labels: {predicted_labels},{len(predicted_labels)}\")\n",
        "\n",
        "if predicted_labels and true_labels:\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    metrics = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "    classification_report_output = classification_report(true_labels, predicted_labels, target_names=['positive', 'negative'])\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {metrics[0]}\")\n",
        "    print(f\"Recall: {metrics[1]}\")\n",
        "    print(f\"F1-score: {metrics[2]}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report_output)\n",
        "else:\n",
        "    print(\"Error: No predicted labels were returned.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a55dkThmLQJ",
        "outputId": "269dfa9e-2aff-44d6-e65a-10c753b026f5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts: ['@user You are a stand up guy and a Gentleman Vice President Pence ', \"i'm not even catholic, but pope francis is my dude. like i just need him to hug me and tell me everything is okay. \", 'Samsung to Bring Android 7.0 Nougat to Galaxy S6, S6 edge, Note 5, and Tab S2 - Softpedia News ', \"I will go so far to say s1 of westworld isn't just good, it's brilliant. A story within a story within a story about storytelling \", '#NationalFastFoodDay Would love to live there. Chick-fil-A üòç ', 'Trying to have a conversation with my dad about vegetarianism is the most pointless infuriating thing ever #caveman ', \"@user @user @user Looks like Flynn isn't too pleased with me, he blocked me. You blocked by Flynn too @user \", '@user for al the crying you do about how middle America is left out-they have twice as much voting power ', 'Israel deems comatose Gaza man who needs treatment in West Bank  a security threat. #Palestine  via @user ', 'Iraqi Forces set to storm 3 areas of #Mosul, #AlQahira, #alMasarif &  #alAmn#MosulOps#mosuloffensive#iraq#ISIS‚Ä¶ ']\n",
            "Response:ChatCompletion(id='chatcmpl-940ZghwpHn7Mb84UsUvdrzrwbN2CZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='positive  \\npositive  \\npositive  \\npositive  \\npositive  \\nnegative  \\nnegative  \\nnegative  \\nnegative  \\npositive', role='assistant', function_call=None, tool_calls=None))], created=1710742548, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=19, prompt_tokens=398, total_tokens=417))\n",
            "Predicted Sentiment: positive  \n",
            "Modified Sentiment: positive\n",
            "Predicted Sentiment: positive  \n",
            "Modified Sentiment: positive\n",
            "Predicted Sentiment: positive  \n",
            "Modified Sentiment: positive\n",
            "Predicted Sentiment: positive  \n",
            "Modified Sentiment: positive\n",
            "Predicted Sentiment: positive  \n",
            "Modified Sentiment: positive\n",
            "Predicted Sentiment: negative  \n",
            "Modified Sentiment: negative\n",
            "Predicted Sentiment: negative  \n",
            "Modified Sentiment: negative\n",
            "Predicted Sentiment: negative  \n",
            "Modified Sentiment: negative\n",
            "Predicted Sentiment: negative  \n",
            "Modified Sentiment: negative\n",
            "Predicted Sentiment: positive\n",
            "Modified Sentiment: positive\n",
            "predicted_labels: ['positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive']\n",
            "True Labels: ['positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative'],10\n",
            "Predicted Labels: ['positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive'],10\n",
            "Accuracy: 0.9\n",
            "Precision: 0.9166666666666667\n",
            "Recall: 0.9\n",
            "F1-score: 0.898989898989899\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       1.00      0.80      0.89         5\n",
            "    negative       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.90        10\n",
            "   macro avg       0.92      0.90      0.90        10\n",
            "weighted avg       0.92      0.90      0.90        10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import openai\n",
        "\n",
        "def extract_alone_sentiment(response):\n",
        "    sentiment = response.choices[0].message.content.split(\"\\n\")[1].strip()\n",
        "    return sentiment\n",
        "\n",
        "def query_gpt(prompts):\n",
        "    openai.api_key = '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'\n",
        "    messages = [{\"role\": \"system\", \"content\": f\"You are an expert in predicting the sentiment of all the given '{len(prompts)}' prompts. You will exactly return one of 'positive' or 'negative' in lowercases for each of the prompt without any prefix.\"}]\n",
        "\n",
        "    user_prompts = []\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        user_prompt = f\"Predict for this prompt: '{prompt}'.\"\n",
        "        user_prompts.append(user_prompt)\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": \"\\n\".join(user_prompts)})\n",
        "\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        print(f\"Response:{response}\")\n",
        "        predicted_labels = []\n",
        "\n",
        "        # Extracting predicted sentiments\n",
        "        for sentiment in response.choices[0].message.content.split(\"\\n\"):\n",
        "            if sentiment:  # Exclude empty lines\n",
        "                # Split by \":\" and take the last part\n",
        "                print(f\"Predicted Sentiment: {sentiment}\")\n",
        "                sentiment = sentiment.split(\": \")[-1].strip()\n",
        "                print(f\"Modified Sentiment: {sentiment}\")\n",
        "                predicted_labels.append(sentiment)\n",
        "        print(f\"predicted_labels: {predicted_labels}\")\n",
        "        return predicted_labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the OpenAI API request: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "dataset = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\", split='test')\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "N = 5\n",
        "\n",
        "positive_samples = [sample for sample, label_id in zip(dataset['text'], dataset['label']) if labels[label_id] == 'positive'][:N]\n",
        "negative_samples = [sample for sample, label_id in zip(dataset['text'], dataset['label']) if labels[label_id] == 'negative'][:N]\n",
        "prompts = positive_samples + negative_samples\n",
        "\n",
        "true_labels.extend(['positive'] * N + ['negative'] * N)\n",
        "\n",
        "print(f\"Prompts: {prompts}\")\n",
        "predicted_labels = query_gpt(prompts)\n",
        "print(f\"True Labels: {true_labels},{len(true_labels)}\")\n",
        "print(f\"Predicted Labels: {predicted_labels},{len(predicted_labels)}\")\n",
        "\n",
        "if predicted_labels and true_labels:\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    metrics = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
        "    classification_report_output = classification_report(true_labels, predicted_labels, target_names=['positive', 'negative'])\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {metrics[0]}\")\n",
        "    print(f\"Recall: {metrics[1]}\")\n",
        "    print(f\"F1-score: {metrics[2]}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report_output)\n",
        "else:\n",
        "    print(\"Error: No predicted labels were returned.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alU2pqfgM-g2",
        "outputId": "162ff32a-1bab-4992-f78e-026d94efa7c4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts: ['@user You are a stand up guy and a Gentleman Vice President Pence ', \"i'm not even catholic, but pope francis is my dude. like i just need him to hug me and tell me everything is okay. \", 'Samsung to Bring Android 7.0 Nougat to Galaxy S6, S6 edge, Note 5, and Tab S2 - Softpedia News ', \"I will go so far to say s1 of westworld isn't just good, it's brilliant. A story within a story within a story about storytelling \", '#NationalFastFoodDay Would love to live there. Chick-fil-A üòç ', 'The Reputation Doctor weighs in on Tony Romo #NFL @user joins @user on #TheMorningRush LISTEN: ', 'So proud of way @user & #trumpTransitionteam are molding strong leadership group for #America #TeamTrump #MakeAmericaGreatAgain ', '@user @user - #ScreamQueens so lucky to get to work with TK. ', 'This is a big deal and a smart move by Microsoft: ', 'Digesting while watching #ScreamQueens s1 Thanksgiving & Black Friday eps. SO SO GOOD!! ', \"I've been listening to Leonard Cohen nonstop for the past month. Only to find out he passed literally weeks ago. Wow my heart is so overwhel \", 'Listen to #NBAwards Winner @user interview on @user ', \"Kelly Anne Conway is here reporting the wall is a glorious 10 meters high, while Ben Carson counters that 'meters' arent even a real thing \", 'Grayson Allen & Lonzo Ball the best players in college basketball. ', \"FINALLY watching Love & Happiness!!!  This country is going to miss your family's class, wisdom, love, and patience. #ThankYouObama \", '#MPN #OneDirection#MtvStarsNiallHoran JESUSüòçüòçüòçüòçüòç ', \"If you wanna have some seasonal fun & #teachecon #Hatchimals are today's Cabbage Patch Kids & Tickle Me Elmo Christ‚Ä¶ \", 'Look at Kierra doing her good singing and growling today. #ThankYouObama ', '#ThisIsUs = my new fav series üëäüèæ ', \"It's incredible how many people are born in November... if u think about it, that means they were conceived in february...(VALENTINES DAY) \", 'I liked a @user video from @user Persona 5 - E3 Gameplay Analysis ', \"Our #MannequinChallenge it's only 10 secs tho üòÇüòÇüòÇ \", \"Yeah where's season 2 gonna go? Incredible season finale yo #WestWorld \", 'Bob Dylan is the greatest. ', \"So is @user gonna sing the #BeautyAndTheBeast theme song? Cos I mean it'd be really great if she did. It'd be perfect, actually... \", 'Trying to have a conversation with my dad about vegetarianism is the most pointless infuriating thing ever #caveman ', \"@user @user @user Looks like Flynn isn't too pleased with me, he blocked me. You blocked by Flynn too @user \", '@user for al the crying you do about how middle America is left out-they have twice as much voting power ', 'Israel deems comatose Gaza man who needs treatment in West Bank  a security threat. #Palestine  via @user ', 'Iraqi Forces set to storm 3 areas of #Mosul, #AlQahira, #alMasarif &  #alAmn#MosulOps#mosuloffensive#iraq#ISIS‚Ä¶ ', 'Electoral College must reject Trump #rejecttrump #notmypresident #takingbackdemocracy #blacklivesmatter #nevertrump ', 'Stop #fracking #Cuadrilla persecuting land defenders through the legal system #BankruptCuadrilla #ECOCIDE ', \"@user Everyone's thinking far too short-termed. When all fossil fuels run out with no substitutes, then the crisis will come. \", '@user @user @user Why is it that today society is casually comfortable about being pubicly distasteful?#deplorables ', \"Ben Carson for Housing & Urban Development?? üòê I just can't üòí \", \"Israel's New Racism: Persecution of African Migrants in Holy Land #gaza #palestine #israel #BDS \", \"@user She just didn't get them in areas were she needed them. Lots of voter suppression going on. Hacking & tamperingüíô \", 'Pelosi should go no matter ', \"I'm doing a speech on animal testing and it is so fucking horrible oh my god \", \"@user Coward... well... why doesn't Poroshenko or Avakov or Saakasjvili travel to Crimea? \", \"-- @user your statement for Mitt to apologize is not a qualifier for him as SOS Trump's transition is ASKING its an Insult. \", '@user last thing @user needs is a self-promoting $ laundering medicare fraud scammer, voter fraud.. rese‚Ä¶ ', 'This reminds me of that time I got attacked by Alt-rightists: ', 'Taylor Shit doing the #mannequinchallenge here in the great state of Rhode Island means that the mannequin challenge is #cancelled. ', '\"Are we out of touch, sexually deviant, decadent dilettantes who can\\'t own up to our misrule?No it is the deplora‚Ä¶ ', 'Mooreder When Michael Moore picks up your cause, then wrecks you. \"He so called out the DNC! It was mooreder I tells ya!\" #UsefulNewVerbs ', \"Donald Trump does not have a clue about global warming. Maybe the Rockefeller's can clue them in about fossil fuels. \", '#TV #Bullshit They are saying #Brexit was not about Closing borders and leaving the single market?? FUNNY THAT ?? STOP BULLSHITING US ', '‚ÄúPharmaceutical companies are being affected by these lower numbers in so many states across the country.‚Äù ', '@user By this logic, we shouldn\\'t have lifted embargo on Cuba b/c it was \"long standing policy.\" ']\n",
            "Response:ChatCompletion(id='chatcmpl-940btBBlpcacPHh9XzbGSMm98Ojng', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Predict the sentiment of the following prompt (1/50): \\'@user You are a stand up guy and a Gentleman Vice President Pence \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (2/50): \\'i\\'m not even catholic, but pope francis is my dude. like i just need him to hug me and tell me everything is okay. \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (3/50): \\'Samsung to Bring Android 7.0 Nougat to Galaxy S6, S6 edge, Note 5, and Tab S2 - Softpedia News \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (4/50): \\'I will go so far to say s1 of westworld isn\\'t just good, it\\'s brilliant. A story within a story within a story about storytelling \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (5/50): \\'#NationalFastFoodDay Would love to live there. Chick-fil-A üòç \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (6/50): \\'The Reputation Doctor weighs in on Tony Romo #NFL @user joins @user on #TheMorningRush LISTEN: \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (7/50): \\'So proud of way @user & #trumpTransitionteam are molding strong leadership group for #America #TeamTrump #MakeAmericaGreatAgain \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (8/50): \\'@user @user - #ScreamQueens so lucky to get to work with TK. \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (9/50): \\'This is a big deal and a smart move by Microsoft: \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (10/50): \\'Digesting while watching #ScreamQueens s1 Thanksgiving & Black Friday eps. SO SO GOOD!! \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (11/50): \\'I\\'ve been listening to Leonard Cohen nonstop for the past month. Only to find out he passed literally weeks ago. Wow my heart is so overwhel \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (12/50): \\'Listen to #NBAwards Winner @user interview on @user \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (13/50): \\'Kelly Anne Conway is here reporting the wall is a glorious 10 meters high, while Ben Carson counters that \\'meters\\' arent even a real thing \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (14/50): \\'Grayson Allen & Lonzo Ball the best players in college basketball. \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (15/50): \\'FINALLY watching Love & Happiness!!!  This country is going to miss your family\\'s class, wisdom, love, and patience. #ThankYouObama \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (16/50): \\'#MPN #OneDirection#MtvStarsNiallHoran JESUSüòçüòçüòçüòçüòç \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (17/50): \\'If you wanna have some seasonal fun & #teachecon #Hatchimals are today\\'s Cabbage Patch Kids & Tickle Me Elmo Christ‚Ä¶ \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (18/50): \\'Look at Kierra doing her good singing and growling today. #ThankYouObama \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (19/50): \\'#ThisIsUs = my new fav series üëäüèæ \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (20/50): \\'It\\'s incredible how many people are born in November... if u think about it, that means they were conceived in february...(VALENTINES DAY) \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (21/50): \\'I liked a @user video from @user Persona 5 - E3 Gameplay Analysis \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (22/50): \\'Our #MannequinChallenge it\\'s only 10 secs tho üòÇüòÇüòÇ \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (23/50): \\'Yeah where\\'s season 2 gonna go? Incredible season finale yo #WestWorld \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (24/50): \\'Bob Dylan is the greatest. \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (25/50): \\'So is @user gonna sing the #BeautyAndTheBeast theme song? Cos I mean it\\'d be really great if she did. It\\'d be perfect, actually... \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (26/50): \\'Trying to have a conversation with my dad about vegetarianism is the most pointless infuriating thing ever #caveman \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (27/50): \\'@user @user @user Looks like Flynn isn\\'t too pleased with me, he blocked me. You blocked by Flynn too @user \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (28/50): \\'@user for al the crying you do about how middle America is left out-they have twice as much voting power \\' into one of the following: positive \\n\\nPredict the sentiment of the following prompt (29/50): \\'Israel deems comatose Gaza man who needs treatment in West Bank  a security threat. #Palestine  via @user \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (30/50): \\'Iraqi Forces set to storm 3 areas of #Mosul, #AlQahira, #alMasarif &  #alAmn#MosulOps#mosuloffensive#iraq#ISIS‚Ä¶ \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (31/50): \\'Electoral College must reject Trump #rejecttrump #notmypresident #takingbackdemocracy #blacklivesmatter #nevertrump \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (32/50): \\'Stop #fracking #Cuadrilla persecuting land defenders through the legal system #BankruptCuadrilla #ECOCIDE \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (33/50): \\'@user Everyone\\'s thinking far too short-termed. When all fossil fuels run out with no substitutes, then the crisis will come. \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (34/50): \\'@user @user @user Why is it that today society is casually comfortable about being pubicly distasteful?#deplorables \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (35/50): \\'Ben Carson for Housing & Urban Development?? üòê I just can\\'t üòí \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (36/50): \\'Israel\\'s New Racism: Persecution of African Migrants in Holy Land #gaza #palestine #israel #BDS \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (37/50): \\'@user She just didn\\'t get them in areas were she needed them. Lots of voter suppression going on. Hacking & tamperingüíô \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (38/50): \\'Pelosi should go no matter \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (39/50): \\'I\\'m doing a speech on animal testing and it is so fucking horrible oh my god \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (40/50): \\'@user Coward... well... why doesn\\'t Poroshenko or Avakov or Saakasjvili travel to Crimea? \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (41/50): \\'-- @user your statement for Mitt to apologize is not a qualifier for him as SOS Trump\\'s transition is ASKING its an Insult. \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (42/50): \\'@user last thing @user needs is a self-promoting $ laundering medicare fraud scammer, voter fraud.. rese‚Ä¶ \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (43/50): \\'This reminds me of that time I got attacked by Alt-rightists: \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (44/50): \\'Taylor Shit doing the #mannequinchallenge here in the great state of Rhode Island means that the mannequin challenge is #cancelled. \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (45/50): \\'\"Are we out of touch, sexually deviant, decadent dilettantes who can\\'t own up to our misrule?No it is the deplora‚Ä¶ \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (46/50): \\'Mooreder When Michael Moore picks up your cause, then wrecks you. \"He so called out the DNC! It was mooreder I tells ya!\" #UsefulNewVerbs \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (47/50): \\'Donald Trump does not have a clue about global warming. Maybe the Rockefeller\\'s can clue them in about fossil fuels. \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (48/50): \\'#TV #Bullshit They are saying #Brexit was not about Closing borders and leaving the single market?? FUNNY THAT ?? STOP BULLSHITING US \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (49/50): \\'‚ÄúPharmaceutical companies are being affected by these lower numbers in so many states across the country.‚Äù \\' into one of the following: negative \\n\\nPredict the sentiment of the following prompt (50/50): \\'@user By this logic, we shouldn\\'t have lifted embargo on Cuba b/c it was \"long standing policy.\" \\' into one of the following: negative', role='assistant', function_call=None, tool_calls=None))], created=1710742685, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=2298, prompt_tokens=3472, total_tokens=5770))\n",
            "Sentiment:\n",
            "An error occurred during the OpenAI API request: list index out of range\n",
            "True Labels: ['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative'],50\n",
            "Predicted Labels: ,0\n",
            "Error: No predicted labels were returned.\n"
          ]
        }
      ]
    }
  ]
}